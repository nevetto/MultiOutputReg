{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBOMmncQ2cvW0Hp0uF4yoY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nevetto/MultiOutputReg/blob/main/MultipleOutputInML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQFsgl7zoX97",
        "outputId": "1ded991c-304b-4a2f-9273-4fc41f9db5c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.2\n"
          ]
        }
      ],
      "source": [
        "# check scikit-learn version\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# summarize dataset\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVuakD5YohGW",
        "outputId": "efb9991e-224c-4e17-a74f-bf30f50eee0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10) (1000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some regression machine learning algorithms support multiple outputs directly.\n",
        "\n",
        "This includes most of the popular machine learning algorithms implemented in the scikit-learn library, such as:\n",
        "\n",
        "LinearRegression (and related)\n",
        "KNeighborsRegressor\n",
        "DecisionTreeRegressor\n",
        "RandomForestRegressor (and related)"
      ],
      "metadata": {
        "id": "SyDCLRb8o2dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression for multioutput regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = LinearRegression()\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make a prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = model.predict([row])\n",
        "# summarize prediction\n",
        "print(yhat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlmywK2ipfC7",
        "outputId": "3df8dcdc-5660-4a7e-8916-95774c54dd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50.06781717 64.564973  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# k-nearest neighbors for multioutput regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = KNeighborsRegressor()\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make a prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = model.predict([row])\n",
        "# summarize prediction\n",
        "print(yhat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCgKHk5spmZz",
        "outputId": "c887108f-ce4f-412c-e14c-17b134941eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-11.73511093  52.78406297]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree for multioutput regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = DecisionTreeRegressor()\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make a prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = model.predict([row])\n",
        "# summarize prediction\n",
        "print(yhat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQy8ISgEqNnV",
        "outputId": "3a1baf45-0076-4023-f664-03a28d520333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[49.93137149 64.08484989]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate multioutput regression model with k-fold cross-validation\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = DecisionTreeRegressor()\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "# force the scores to be positive\n",
        "n_scores = absolute(n_scores)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qLBgKAmqbIX",
        "outputId": "8869fba5-6a2f-41ac-f2fe-41cc3e24229c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 52.807 (3.301)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
        "\n",
        "Importantly, error is reported across both output variables, rather than separate error scores for each output variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "G8D-2W1BqyR1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4VbrDazPqwkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not all regression algorithms support multioutput regression.\n",
        "\n",
        "One example is the support vector machine, although for regression, it is referred to as support vector regression, or SVR.\n",
        "\n",
        "This algorithm does not support multiple outputs for a regression problem and will raise an error. We can demonstrate this with an example, listed below.\n",
        "\n"
      ],
      "metadata": {
        "id": "rKAVp5WPrswi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# failure of support vector regression for multioutput regression (causes an error)\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.svm import LinearSVR\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n",
        "# define model\n",
        "model = LinearSVR()\n",
        "# fit model\n",
        "# (THIS WILL CAUSE AN ERROR!)\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "Ml9DKcDTrwa7",
        "outputId": "2360d020-45f7-4772-f760-26e41dc79da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c503f6a1d7de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# (THIS WILL CAUSE AN ERROR!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         )\n\u001b[1;32m    483\u001b[0m         \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"l2\"\u001b[0m  \u001b[0;31m# SVR only accepts l2 penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    991\u001b[0m         )\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     raise ValueError(\n\u001b[0;32m-> 1039\u001b[0;31m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     )\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (1000, 2) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A workaround for using regression models designed for predicting one value for multioutput regression is to divide the multioutput regression problem into multiple sub-problems.\n",
        "\n",
        "The most obvious way to do this is to split a multioutput regression problem into multiple single-output regression problems.\n",
        "\n",
        "For example, if a multioutput regression problem required the prediction of three values y1, y2 and y3 given an input X, then this could be partitioned into three single-output regression problems:\n",
        "\n",
        "Problem 1: Given X, predict y1.\n",
        "Problem 2: Given X, predict y2.\n",
        "Problem 3: Given X, predict y3.\n",
        "There are two main approaches to implementing this technique.\n",
        "\n",
        "The first approach involves developing a separate regression model for each output value to be predicted. We can think of this as a direct approach, as each target value is modeled directly.\n",
        "\n",
        "The second approach is an extension of the first method except the models are organized into a chain. The prediction from the first model is taken as part of the input to the second model, and the process of output-to-input dependency repeats along the chain of models.\n",
        "\n",
        "Direct Multioutput: Develop an independent model for each numerical value to be predicted.\n",
        "\n",
        "\n",
        "Chained Multioutput: Develop a sequence of dependent models to match the number of numerical values to be predicted.\n",
        "Let’s take a closer look at each of these techniques in turn."
      ],
      "metadata": {
        "id": "1KdB3S44sKnG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Direct Multioutput Regression\n",
        "The direct approach to multioutput regression involves dividing the regression problem into a separate problem for each target variable to be predicted.\n",
        "\n",
        "This assumes that the outputs are independent of each other, which might not be a correct assumption. Nevertheless, this approach can provide surprisingly effective predictions on a range of problems and may be worth trying, at least as a performance baseline.\n",
        "\n",
        "For example, the outputs for your problem may, in fact, be mostly independent, if not completely independent, and this strategy can help you find out.\n",
        "\n",
        "This approach is supported by the MultiOutputRegressor class that takes a regression model as an argument. It will then create one instance of the provided model for each output in the problem.\n",
        "\n",
        "The example below demonstrates how we can first create a single-output regression model then use the MultiOutputRegressor class to wrap the regression model and add support for multioutput regression."
      ],
      "metadata": {
        "id": "1zIV7CTPLTNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of evaluating direct multioutput regression with an SVM model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import absolute\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define base model\n",
        "model = LinearSVR()\n",
        "# define the direct multioutput wrapper model\n",
        "wrapper = MultiOutputRegressor(model)\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(wrapper, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "# force the scores to be positive\n",
        "n_scores = absolute(n_scores)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "CNiDEnUdsMdy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e328e9a-a632-4f45-dd03-bbca7c73e682"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.419 (0.024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the direct multioutput regression wrapper as a final model and make predictions on new data.\n",
        "\n",
        "First, the model is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
        "\n",
        "The example below demonstrates this on our synthetic multioutput regression dataset."
      ],
      "metadata": {
        "id": "FIn-dxd8Mcmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of making a prediction with the direct multioutput regression model\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define base model\n",
        "model = LinearSVR()\n",
        "# define the direct multioutput wrapper model\n",
        "wrapper = MultiOutputRegressor(model)\n",
        "# fit the model on the whole dataset\n",
        "wrapper.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = wrapper.predict([row])\n",
        "# summarize the prediction\n",
        "print('Predicted: %s' % yhat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWBttAa1McOy",
        "outputId": "6362caa6-a8f0-49b2-d3e6-8eca8b800abb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [50.03273556 64.51825665]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chained Multioutput Regression\n",
        "Another approach to using single-output regression models for multioutput regression is to create a linear sequence of models.\n",
        "\n",
        "The first model in the sequence uses the input and predicts one output; the second model uses the input and the output from the first model to make a prediction; the third model uses the input and output from the first two models to make a prediction, and so on.\n",
        "\n",
        "For example, if a multioutput regression problem required the prediction of three values y1, y2 and y3 given an input X, then this could be partitioned into three dependent single-output regression problems as follows:\n",
        "\n",
        "Problem 1: Given X, predict y1.\n",
        "Problem 2: Given X and yhat1, predict y2.\n",
        "Problem 3: Given X, yhat1, and yhat2, predict y3.\n",
        "This can be achieved using the RegressorChain class in the scikit-learn library.\n",
        "\n",
        "The order of the models may be based on the order of the outputs in the dataset (the default) or specified via the “order” argument. For example, order=[0,1] would first predict the oth output, then the 1st output, whereas an order=[1,0] would first predict the last output variable and then the first output variable in our test problem.\n",
        "\n",
        "The example below demonstrates how we can first create a single-output regression model then use the RegressorChain class to wrap the regression model and add support for multioutput regression.\n",
        "\n",
        "We can demonstrate this strategy with a worked example on our synthetic multioutput regression problem.\n",
        "\n",
        "The example below demonstrates evaluating the RegressorChain class with linear SVR using repeated k-fold cross-validation and reporting the average mean absolute error (MAE) across all folds and repeats.\n",
        "\n",
        "The complete example is listed below."
      ],
      "metadata": {
        "id": "gtZYHac-QTTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of evaluating chained multioutput regression with an SVM model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import absolute\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.svm import LinearSVR\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define base model\n",
        "model = LinearSVR()\n",
        "# define the chained multioutput wrapper model\n",
        "wrapper = RegressorChain(model)\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(wrapper, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "# force the scores to be positive\n",
        "n_scores = absolute(n_scores)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPBKU_twTTaL",
        "outputId": "5ccd4226-87d8-4ab5-a61a-70b384c3de31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.633 (0.251)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of making a prediction with the chained multioutput regression model\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import RegressorChain\n",
        "from sklearn.svm import LinearSVR\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define base model\n",
        "model = LinearSVR()\n",
        "# define the chained multioutput wrapper model\n",
        "wrapper = RegressorChain(model)\n",
        "# fit the model on the whole dataset\n",
        "wrapper.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = wrapper.predict([row])\n",
        "# summarize the prediction\n",
        "print('Predicted: %s' % yhat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rG6Uh7dQSFd",
        "outputId": "94252d87-9c9e-42cd-d6de-11010fdd079b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [50.02536581 64.65584581]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    }
  ]
}